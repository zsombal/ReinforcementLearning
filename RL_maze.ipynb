{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.28932586  0.07612785  0.86436043  0.30766699]\n",
      " [ 0.58303943  0.41929991  0.03794535  0.45105288]\n",
      " [ 0.16696255  0.59824931  0.59536509  0.76882215]]\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "[[1 1 1 0]\n",
      " [1 0 1 0]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Set up the initial V-values, you can do 0 or random\n",
    "import numpy as np\n",
    "V = np.zeros([3,4])\n",
    "V = np. random.rand(3,4)\n",
    "print V\n",
    "\n",
    "# Set up Rewards\n",
    "R = np.zeros([3,4])\n",
    "R[0,3] = 1\n",
    "R[1,3] = -1\n",
    "print R\n",
    "\n",
    "# Set up the enter, exit cells, as well as inaccessible cells, all of these are denoted by a zero in this matrix\n",
    "PI_bool = np.array([[1,1,1,0],[1,0,1,0],[1,1,1,1]])\n",
    "print PI_bool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1 2 3 0]\n",
      "   [0 0 3 0]\n",
      "   [1 2 3 3]]\n",
      "\n",
      "  [[0 0 1 0]\n",
      "   [0 0 2 0]\n",
      "   [0 0 1 2]]\n",
      "\n",
      "  [[0 1 2 3]\n",
      "   [0 1 2 3]\n",
      "   [0 1 2 3]]\n",
      "\n",
      "  [[0 1 2 3]\n",
      "   [0 1 2 3]\n",
      "   [0 1 2 3]]]\n",
      "\n",
      "\n",
      " [[[0 0 0 0]\n",
      "   [1 1 1 1]\n",
      "   [2 2 2 2]]\n",
      "\n",
      "  [[0 0 0 0]\n",
      "   [1 1 1 1]\n",
      "   [2 2 2 2]]\n",
      "\n",
      "  [[0 0 0 0]\n",
      "   [0 0 0 0]\n",
      "   [1 2 1 1]]\n",
      "\n",
      "  [[1 0 1 0]\n",
      "   [2 0 2 0]\n",
      "   [2 2 2 2]]]]\n"
     ]
    }
   ],
   "source": [
    "# different policies defined here\n",
    "\n",
    "# 2 (i or j) x 4 (right, left, up, down) x 3 (state's i position) x 4 (state's j position)\n",
    "\n",
    "PI = np.zeros([2,4,3,4], dtype=int)\n",
    "\n",
    "## j\n",
    "PI[1,0,:,:] = np.array([[0,0,0,0],[1,1,1,1],[2,2,2,2]])\n",
    "PI[1,1,:,:] = np.array([[0,0,0,0],[1,1,1,1],[2,2,2,2]])\n",
    "PI[1,2,:,:] = np.array([[0,0,0,0],[0,0,0,0],[1,2,1,1]])\n",
    "PI[1,3,:,:] = np.array([[1,0,1,0],[2,0,2,0],[2,2,2,2]])\n",
    "\n",
    "## ii\n",
    "PI[0,0,:,:] = np.array([[1,2,3,0],[0,0,3,0],[1,2,3,3]])\n",
    "PI[0,1,:,:] = np.array([[0,0,1,0],[0,0,2,0],[0,0,1,2]])\n",
    "PI[0,2,:,:] = np.array([[0,1,2,3],[0,1,2,3],[0,1,2,3]])\n",
    "PI[0,3,:,:] = np.array([[0,1,2,3],[0,1,2,3],[0,1,2,3]])\n",
    "# PI[0,0,:,:] = np.array([[1,2,3,np.nan],[0,np.nan,3,np.nan],[1,2,3,3]])\n",
    "# PI[0,1,:,:] = np.array([[0,0,1,np.nan],[0,np.nan,2,np.nan],[0,0,1,2]])\n",
    "# PI[0,2,:,:] = np.array([[0,0,0,np.nan],[0,np.nan,0,np.nan],[1,2,1,1]])\n",
    "# PI[0,3,:,:] = np.array([[1,0,1,np.nan],[2,np.nan,2,np.nan],[2,2,2,2]])\n",
    "\n",
    "print PI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look how a single policy update looks like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIGHT policy reward\n",
      "[[ 0.  0.  1.  0.]\n",
      " [ 0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "LEFT policy reward\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "UP policy reward\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.]]\n",
      "DOWN policy reward\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# print PI[0,0,:,:]\n",
    "# print PI[1,0,:,:]\n",
    "\n",
    "print 'RIGHT policy reward'\n",
    "print R[PI[1,0,:,:], PI[0,0,:,:]] * PI_bool\n",
    "print 'LEFT policy reward'\n",
    "print R[PI[1,1,:,:], PI[0,1,:,:]] * PI_bool\n",
    "print 'UP policy reward'\n",
    "print R[PI[1,2,:,:], PI[0,2,:,:]] * PI_bool\n",
    "print 'DOWN policy reward'\n",
    "print R[PI[1,3,:,:], PI[0,3,:,:]] * PI_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIGHT policy value\n",
      "[[ 0.07612785  0.86436043  0.30766699  0.        ]\n",
      " [ 0.58303943  0.          0.45105288  0.        ]\n",
      " [ 0.59824931  0.59536509  0.76882215  0.76882215]]\n",
      "LEFT policy value\n",
      "[[ 0.28932586  0.28932586  0.07612785  0.        ]\n",
      " [ 0.58303943  0.          0.03794535  0.        ]\n",
      " [ 0.16696255  0.16696255  0.59824931  0.59536509]]\n",
      "UP policy value\n",
      "[[ 0.28932586  0.07612785  0.86436043  0.        ]\n",
      " [ 0.28932586  0.          0.86436043  0.        ]\n",
      " [ 0.58303943  0.59824931  0.03794535  0.45105288]]\n",
      "DOWN policy value\n",
      "[[ 0.58303943  0.07612785  0.03794535  0.        ]\n",
      " [ 0.16696255  0.          0.59536509  0.        ]\n",
      " [ 0.16696255  0.59824931  0.59536509  0.76882215]]\n"
     ]
    }
   ],
   "source": [
    "print 'RIGHT policy value'\n",
    "print V[PI[1,0,:,:], PI[0,0,:,:]] * PI_bool\n",
    "print 'LEFT policy value'\n",
    "print V[PI[1,1,:,:], PI[0,1,:,:]] * PI_bool\n",
    "print 'UP policy value'\n",
    "print V[PI[1,2,:,:], PI[0,2,:,:]] * PI_bool\n",
    "print 'DOWN policy value'\n",
    "print V[PI[1,3,:,:], PI[0,3,:,:]] * PI_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the value update functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(R, PI, gamma = 1):\n",
    "    #gamma = 1\n",
    "    # just a right step\n",
    "    RS = (R[PI[1,0,:,:], PI[0,0,:,:]] * PI_bool + gamma * V[PI[1,0,:,:], PI[0,0,:,:]] * PI_bool)\n",
    "    #print RS\n",
    "    # just a left step\n",
    "    LS = (R[PI[1,1,:,:], PI[0,1,:,:]] * PI_bool + gamma * V[PI[1,1,:,:], PI[0,1,:,:]] * PI_bool)\n",
    "    #print LS\n",
    "    # just an up step\n",
    "    US = (R[PI[1,2,:,:], PI[0,2,:,:]] * PI_bool + gamma * V[PI[1,2,:,:], PI[0,2,:,:]] * PI_bool)\n",
    "    #print US\n",
    "    # just a down step\n",
    "    DS = (R[PI[1,3,:,:], PI[0,3,:,:]] * PI_bool + gamma * V[PI[1,3,:,:], PI[0,3,:,:]] * PI_bool)\n",
    "    #print DS\n",
    "    return RS, LS, US, DS\n",
    "RS, LS, US, DS = get_steps(R, PI, gamma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_V(RS, LS, US, DS):\n",
    "    # A right policy update consists of 0.8*(RIGHT step) + 0.1*(UP step) + 0.1*(DOWN step)\n",
    "    VR = 0.8*RS+0.1*US+0.1*DS\n",
    "    #print VR\n",
    "    VL = 0.8*LS+0.1*US+0.1*DS\n",
    "    #print VL\n",
    "    VU = 0.8*US+0.1*LS+0.1*RS\n",
    "    #print VU\n",
    "    VD = 0.8*DS+0.1*LS+0.1*RS\n",
    "    #print VD\n",
    "    #print 'maximum'\n",
    "    V_new = np.array([VR, VL, VU, VD]).max(0)\n",
    "    PI_new =  np.array([VR, VL, VU, VD]).argmax(0)\n",
    "    return VR, VL, VU, VD, V_new, PI_new\n",
    "VR, VL, VU, VD, V_new, PI_new = update_V(RS, LS, US, DS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an actual algorithm for Value Iteration\n",
    "\n",
    "don't care about the policy, only care about the last policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right\n",
      "[[ 0.51965897  0.69751844  0.91549296  0.        ]\n",
      " [ 0.31897867  0.         -0.69693632  0.        ]\n",
      " [ 0.23747065  0.28404042  0.16849095  0.00846483]]\n",
      "Left\n",
      "[[ 0.40582891  0.44418469  0.56190476  0.        ]\n",
      " [ 0.31897867  0.          0.44109185  0.        ]\n",
      " [ 0.24776746  0.23752914  0.25386363  0.1506456 ]]\n",
      "Up\n",
      "[[ 0.42995594  0.56122396  0.74171697  0.        ]\n",
      " [ 0.39593065  0.          0.52816901  0.        ]\n",
      " [ 0.30012918  0.23562045  0.37280305 -0.75812411]]\n",
      "Down\n",
      "[[ 0.35076981  0.56122396  0.49382964  0.        ]\n",
      " [ 0.25543158  0.          0.18084747  0.        ]\n",
      " [ 0.23881624  0.23562045  0.27336883  0.13828908]]\n",
      "Max Value\n",
      "[[ 0.51965897  0.69751844  0.91549296  0.        ]\n",
      " [ 0.39593065  0.          0.52816901  0.        ]\n",
      " [ 0.30012918  0.28404042  0.37280305  0.1506456 ]]\n",
      "Optimal Policy\n",
      "[[0 0 0 0]\n",
      " [2 0 2 0]\n",
      " [2 0 2 1]]\n",
      "0 - right, 1 - left, 2 - up, 3 - down\n"
     ]
    }
   ],
   "source": [
    "V = np.zeros([3,4])\n",
    "for i in range(100):\n",
    "#     print i\n",
    "    RS, LS, US, DS = get_steps(R, PI, gamma = 0.8)\n",
    "    VR, VL, VU, VD, V_new, PI_new = update_V(RS, LS, US, DS)\n",
    "    V = V_new\n",
    "print 'Right'\n",
    "print VR\n",
    "print 'Left'\n",
    "print VL\n",
    "print 'Up'\n",
    "print VU\n",
    "print 'Down'\n",
    "print VD\n",
    "print 'Max Value'\n",
    "print V_new\n",
    "print 'Optimal Policy'\n",
    "print PI_new\n",
    "    \n",
    "print '0 - right, 1 - left, 2 - up, 3 - down'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
